{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ff6af4-6d4b-4aef-88c0-e92f4d6fb0b3",
   "metadata": {},
   "source": [
    "# 2. Text and categorical data problems\n",
    "**Categorical and text data can often be some of the messiest parts of a dataset due to their unstructured nature. In this chapter, you’ll learn how to fix whitespace and capitalization inconsistencies in category labels, collapse multiple categories into one, and reformat strings for consistency.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b220e3-d746-4a29-b28a-f1c22cd1d53a",
   "metadata": {},
   "source": [
    "## Membership constraints\n",
    "### Categories and membership constraints\n",
    "**Predifined finite set of categories**\n",
    "\n",
    "Type of data | Example values | Numeric representation\n",
    ":---|:---|:---\n",
    "Marriage Status | `unmarried`, `married` | `0`, `1`\n",
    "Household Income Category | `0-20k`, `20-40k`, ... | `0`, `1`, ...\n",
    "Loan Status | `default`, `payed`, `no_loan` | `0`, `1`, `2`\n",
    "\n",
    "*Marriage status can **only** be `unmarried` _or_ `married`*\n",
    "\n",
    "To run machine learning models on categorical data, they are often coded as numbers. Since categorical data represent a predefined set of categories, they can't have values that go beyond these predefined categories.\n",
    "\n",
    "### Why could we have these problems?\n",
    "We can have inconsistencies in our categorical data for a variety of reasons. This could be due to data entry issues with free text vs dropdown fields, *data parsing errors* and *other types of errors*.\n",
    "\n",
    "### How do we treat these problems?\n",
    "There's a variety of ways we can treat these, with increasingly specific solutions for different types of inconsistencies. Most simply, we can drop the rows with incorrect categories. We can attempt remapping incorrect categories to correct ones, and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89307691-c9c8-4c59-be54-841ac08edbbd",
   "metadata": {},
   "source": [
    "### An example\n",
    "Here's a DataFrame named `study_data` containing a list of first names, birth dates, and blood types. Additionally, a DataFrame named categories, containing the correct possible categories for the blood type column has been created as well.\n",
    "\n",
    "```python\n",
    "# Read study data and print it\n",
    "study_data = pd.read_csv('study.csv')\n",
    "study_data\n",
    "```\n",
    "```\n",
    "       name    birthday    blood_type\n",
    "1      Beth  2019-10-20            B-\n",
    "2  Ignatius  2020-07-08            A-\n",
    "3      Paul  2019-08-12            O+\n",
    "4     Helen  2019-03-17            O-\n",
    "5  Jennifer  2019-12-17            Z+   <--\n",
    "6   Kennedy  2020-04-27            A+\n",
    "7     Keith  2018-04-19           AB+\n",
    "```\n",
    "\n",
    "There's definitely no blood type named `Z+`. \n",
    "\n",
    "Luckily, the `categories` DataFrame will help us systematically spot all rows with these inconsistencies. \n",
    "\n",
    "```python\n",
    "# Correct possible blood types\n",
    "categories\n",
    "```\n",
    "```\n",
    "  blood_type\n",
    "1         O-\n",
    "2         O+\n",
    "3         A-\n",
    "4         A+\n",
    "5         B+\n",
    "6         B-\n",
    "7        AB+\n",
    "8        AB-\n",
    "```\n",
    "\n",
    "It's always good practice to keep a log of all possible values of your categorical data, as it will make dealing with these types of inconsistencies way easier.\n",
    "\n",
    "### A note on joins\n",
    "- Anti Joins: What is **in A and not in B**\n",
    "- Inner Joins: What is **in *both* A and B**\n",
    "\n",
    "### Finding inconsistent categories\n",
    "\n",
    "We first get all inconsistent categories in the `blood_type` column of the `study_data` DataFrame. We do that by creating a set out of the `blood_type` column which stores its unique values, and use the `difference` method which takes in as argument the `blood_type` column from the `categories` DataFrame. \n",
    "\n",
    "```python\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "print(inconsistent_categories)\n",
    "```\n",
    "This returns all the categories in `blood_type` that are not in categories. \n",
    "```\n",
    "{'Z+'}\n",
    "```\n",
    "\n",
    "We then find the inconsistent rows by finding all the rows of the `blood_type` columns that are equal to inconsistent categories by using the `isin` method, this returns a series of boolean values that are `True` for inconsistent rows and `False` for consistent ones. We then subset the `study_data` DataFrame based on these boolean values, \n",
    "\n",
    "```python\n",
    "# Get and print rows with incinsistent categories\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "study_data[inconsistent_rows]\n",
    "```\n",
    "and we have our inconsistent data.\n",
    "```\n",
    "       name    birthday    blood_type\n",
    "5  Jennifer  2019-12-17            Z+\n",
    "```\n",
    "\n",
    "### Dropping inconsistent categories\n",
    "To drop inconsistent rows and keep ones that are only consistent. We just use the tilde(`~`) symbol while subsetting which returns everything except inconsistent rows.\n",
    "\n",
    "```python\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "inconsistent_data = study_data[inconsistent_rows]\n",
    "# Drop inconsistent categories and get consistent data only\n",
    "consistent_data = study_data[~inconsistent_rows]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb6160-ef7a-4138-b8ea-f60c8d1c9313",
   "metadata": {},
   "source": [
    "## Finding consistency\n",
    "In this exercise and throughout this chapter, you'll be working with the `airlines` DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "\n",
    "The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named `categories` was created, containing all correct possible values for the survey columns.\n",
    "\n",
    "In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe853d67-8741-4621-9fd1-3a0dc56b52ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       day      airline        destination    dest_region dest_size  \\\n",
       "0  1351   Tuesday  UNITED INTL             KANSAI           Asia       Hub   \n",
       "1   373    Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico     Small   \n",
       "2  2820  Thursday        DELTA        LOS ANGELES        West US       Hub   \n",
       "\n",
       "  boarding_area   dept_time  wait_min cleanliness         safety  \\\n",
       "0  Gates 91-102  2018-12-31       115       Clean        Neutral   \n",
       "1   Gates 50-59  2018-12-31       135       Clean      Very safe   \n",
       "2   Gates 40-48  2018-12-31        70     Average  Somewhat safe   \n",
       "\n",
       "     satisfaction  \n",
       "0  Very satisfied  \n",
       "1  Very satisfied  \n",
       "2         Neutral  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "airlines = pd.read_csv('airlines.csv', index_col=0)\n",
    "airlines.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb33e4-9c6b-4d36-b213-de60e2d83678",
   "metadata": {},
   "source": [
    "- Print the `categories` DataFrame and take a close look at all possible correct categories of the survey columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518eff9e-e975-4279-b471-47c4105e32ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n"
     ]
    }
   ],
   "source": [
    "# Print categories DataFrame\n",
    "categories = pd.read_csv('categories.csv')\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93128b4-d250-4405-8967-d5c7f099947b",
   "metadata": {},
   "source": [
    "- Print the unique values of the survey columns in `airlines` using the `.unique()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3036da7e-70e7-40d0-b532-a8a1e8f00939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanliness:  ['Clean' 'Average' 'Unacceptable' 'Somewhat clean' 'Somewhat dirty'\n",
      " 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e87bfd-29d7-4783-a2a0-dcd2a518c6cf",
   "metadata": {},
   "source": [
    "- Create a set out of the `cleanliness` column in `airlines` using `set()` and find the inconsistent category by finding the **difference** in the `cleanliness` column of `categories`.\n",
    "- Find rows of `airlines` with a `cleanliness` value not in `categories` and print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ec6afbf-1db3-46d6-b06c-fe28ed797cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559</td>\n",
       "      <td>Unacceptable</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2913</td>\n",
       "      <td>Friday</td>\n",
       "      <td>TURKISH AIRLINES</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>225</td>\n",
       "      <td>Unacceptable</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2321</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>130</td>\n",
       "      <td>Unacceptable</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        day           airline  destination  dest_region dest_size  \\\n",
       "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   \n",
       "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub   \n",
       "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   \n",
       "\n",
       "    boarding_area   dept_time  wait_min   cleanliness         safety  \\\n",
       "4     Gates 50-59  2018-12-31       559  Unacceptable      Very safe   \n",
       "18   Gates 91-102  2018-12-31       225  Unacceptable      Very safe   \n",
       "100   Gates 20-39  2018-12-31       130  Unacceptable  Somewhat safe   \n",
       "\n",
       "           satisfaction  \n",
       "4    Somewhat satsified  \n",
       "18   Somewhat satsified  \n",
       "100  Somewhat satsified  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# View rows with inconsistent category\n",
    "display(airlines[cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ced13-6a3b-4112-9c89-d607dde9334e",
   "metadata": {},
   "source": [
    "- Print the rows with the consistent categories of `cleanliness` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55346c4-c580-4c7b-b4c3-31a1c4deeaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>634</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEWARK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>140</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>1475</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEW YORK-JFK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>280</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>2222</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>165</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2684</td>\n",
       "      <td>Friday</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>ORLANDO</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 70-90</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>92</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2549</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>JETBLUE</td>\n",
       "      <td>LONG BEACH</td>\n",
       "      <td>West US</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>95</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>2162</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>CHINA EASTERN</td>\n",
       "      <td>QINGDAO</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Large</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>220</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2474 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       day        airline        destination    dest_region  \\\n",
       "0     1351   Tuesday    UNITED INTL             KANSAI           Asia   \n",
       "1      373    Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
       "2     2820  Thursday          DELTA        LOS ANGELES        West US   \n",
       "3     1157   Tuesday      SOUTHWEST        LOS ANGELES        West US   \n",
       "5      634  Thursday         ALASKA             NEWARK        East US   \n",
       "...    ...       ...            ...                ...            ...   \n",
       "2804  1475   Tuesday         ALASKA       NEW YORK-JFK        East US   \n",
       "2805  2222  Thursday      SOUTHWEST            PHOENIX        West US   \n",
       "2806  2684    Friday         UNITED            ORLANDO        East US   \n",
       "2807  2549   Tuesday        JETBLUE         LONG BEACH        West US   \n",
       "2808  2162  Saturday  CHINA EASTERN            QINGDAO           Asia   \n",
       "\n",
       "     dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
       "0          Hub  Gates 91-102  2018-12-31       115           Clean   \n",
       "1        Small   Gates 50-59  2018-12-31       135           Clean   \n",
       "2          Hub   Gates 40-48  2018-12-31        70         Average   \n",
       "3          Hub   Gates 20-39  2018-12-31       190           Clean   \n",
       "5          Hub   Gates 50-59  2018-12-31       140  Somewhat clean   \n",
       "...        ...           ...         ...       ...             ...   \n",
       "2804       Hub   Gates 50-59  2018-12-31       280  Somewhat clean   \n",
       "2805       Hub   Gates 20-39  2018-12-31       165           Clean   \n",
       "2806       Hub   Gates 70-90  2018-12-31        92           Clean   \n",
       "2807     Small    Gates 1-12  2018-12-31        95           Clean   \n",
       "2808     Large    Gates 1-12  2018-12-31       220           Clean   \n",
       "\n",
       "             safety        satisfaction  \n",
       "0           Neutral      Very satisfied  \n",
       "1         Very safe      Very satisfied  \n",
       "2     Somewhat safe             Neutral  \n",
       "3         Very safe  Somewhat satsified  \n",
       "5         Very safe      Very satisfied  \n",
       "...             ...                 ...  \n",
       "2804        Neutral  Somewhat satsified  \n",
       "2805      Very safe      Very satisfied  \n",
       "2806      Very safe      Very satisfied  \n",
       "2807  Somewhat safe      Very satisfied  \n",
       "2808      Very safe  Somewhat satsified  \n",
       "\n",
       "[2474 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View rows with consistent categories only\n",
    "display(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768ca62-4715-4706-974e-ddfe1809d39d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2dd974-1fa1-428f-be77-2517b9a5a194",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "### What type of errors could we have?\n",
    "1. **Value Inconsistency**\n",
    "    - *Inconsistent fields*: `'married'`, `'Maried'`, `'UNMARRIED'`, `'not married'`...\n",
    "    - _Trailling white spaces: _`'married '`, `' married '` ...\n",
    "\n",
    "\n",
    "2. **Collapsing too many categories to few**\n",
    "    - *Creating new groups*: `0-20k`, `20-40k` categories ... from continuous household income data\n",
    "    - *Mapping groups to new ones*: Mapping household income categories to 2 `'rich'`, `'poor'`\n",
    "\n",
    "\n",
    "3. **Making sure data is of type `category`**\n",
    "\n",
    "### Value consistency\n",
    "A common categorical data problem is having values that slightly differ because of capitalization. Not treating this could lead to misleading results when we decide to analyze our data, for example, let's assume we're working with a demographics dataset, and we have a marriage status column with inconsistent capitalization. \n",
    "\n",
    "***Capitalization***: `'married'`, `'Married'`, `'UNMARRIED'`, `'unmarried'` ...\n",
    "\n",
    "Here's what counting the number of married people in the `marriage_status` Series would look like. Note that the `.value_counts()` methods works on Series only.\n",
    "\n",
    "```python\n",
    "# Get marriage status column\n",
    "marriage_status = demographics['marriage_status']\n",
    "marriage_status.value_counts()\n",
    "```\n",
    "```\n",
    "unmarried    352\n",
    "married      268\n",
    "MARRIED      204\n",
    "UNMARRIED    176\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "\n",
    "For a DataFrame, we can `groupby` the column and use the `.count()` method.\n",
    "```python\n",
    "# Get value counts on DataFrame\n",
    "marriage_status.groupby('marriage_status').count()\n",
    "```\n",
    "```\n",
    "                 household_income  gender\n",
    "marriage_status  \n",
    "MARRIED                       204     204\n",
    "UNMARRIED                     176     176\n",
    "married                       268     268\n",
    "unmarried                     352     352\n",
    "```\n",
    "\n",
    "To deal with this, we can either capitalize or lowercase the marriage_status column. This can be done with the `str.upper()` or `str.lower()` functions respectively.\n",
    "\n",
    "```python\n",
    "# Caplitalize\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str.upper()\n",
    "marriage_status['marriage_status'].value.count()\n",
    "```\n",
    "```\n",
    "UNMARRIED    528\n",
    "MARRIED      472\n",
    "```\n",
    "\n",
    "```python\n",
    "# Lowercase\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str.lower()\n",
    "marriage_status['marriage_status'].value.count()\n",
    "```\n",
    "```\n",
    "unmarried    528\n",
    "married      472\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b3884-8ac5-4751-8829-73c6b5f78af5",
   "metadata": {},
   "source": [
    "Another common problem with categorical values are leading or trailing spaces. \n",
    "\n",
    "***Trailling spaces***: `'married '`, `'married'`, `'unmarried'`, `' unmarried'` ...\n",
    "\n",
    "For example, imagine the same demographics DataFrame containing values with leading spaces. Here's what the counts of married vs unmarried people would look like.\n",
    "\n",
    "```python\n",
    "# Get marriage status column\n",
    "marriage_status = demographics['marriage_status']\n",
    "marriage_status.value_counts()\n",
    "```\n",
    "```\n",
    " unmarried   352\n",
    "unmarried    268\n",
    "married      204\n",
    "married      176\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Note that there is a married category with a trailing space on the right, which makes it hard to spot on the output, as opposed to unmarried.\n",
    "\n",
    "To remove leading spaces, we can use the `str.strip()` method which when given no input, strips all leading and trailing white spaces.\n",
    "```python\n",
    "# Strip all spaces\n",
    "marriage_status = demographics['marriage_status'].str.strip()\n",
    "demographics['marriage_status'].value_counts()\n",
    "```\n",
    "```\n",
    "unmarried    528\n",
    "married      472\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4bbbb-1fe1-40cc-ab4f-aa9c30673da1",
   "metadata": {},
   "source": [
    "### Collapsing data into categories\n",
    "***Create categories out of data***: `income_group` column from `income` column\n",
    "\n",
    "To create categories out of data, let's use the example of creating an income group column in the demographics DataFrame. We can do this in 2 ways. \n",
    "\n",
    "The first method utilizes the `qcut` function from `pandas`, which automatically divides our data based on its distribution into the number of categories we set in the `q` argument, we created the category names in the group_names list and fed it to the labels argument, returning the following. \n",
    "\n",
    "```python\n",
    "# Using qcut()\n",
    "import padnas as pd\n",
    "group_names = ['0-200k', '200-500k', '500k+']\n",
    "demographics['income_group'] = pd.qcut(demographics['household_income'], q = 3, \n",
    "                                       labels = group_names)\n",
    "# Print income_group column\n",
    "demographics[['income_group', 'household_income']]\n",
    "```\n",
    "```\n",
    "     category  household_income\n",
    "0   200k-500k  189243\n",
    "1       500K+  778533\n",
    "...\n",
    "```\n",
    "Notice that the first row actually misrepresents the actual income of the income group, as we didn't instruct qcut where our ranges actually lie.\n",
    "\n",
    "We can do this with the `cut` function instead, which lets us define category cutoff ranges with the `bins` argument. It takes in a list of cutoff points for each category, with the final one being infinity represented with `np.inf()`. From the output, we can see this is much more correct.\n",
    "\n",
    "```python\n",
    "# Using cut() - create category ranges and names\n",
    "ranges = [0, 200000, 500000, np.inf]\n",
    "group_names = ['0-200k', '200-500k', '500k+']\n",
    "# Create income group column\n",
    "demographics['income_group'] = pd.cut(demographics['household_income'], bins=ranges, \n",
    "                                       labels = group_names)\n",
    "# Print income_group column\n",
    "demographics[['income_group', 'household_income']]\n",
    "```\n",
    "```\n",
    "     category  Income\n",
    "0   200k-500k  189243\n",
    "1       500K+  778533\n",
    "```\n",
    "\n",
    "### Collapsing data into categories\n",
    "Sometimes, we may want to reduce the amount of categories we have in our data. Let's move on to mapping categories to fewer ones. For example, assume we have a column containing the operating system of different devices, and contains these unique values. Say we want to collapse these categories into 2, `DesktopOS`, and `MobileOS`. We can do this using the replace method. It takes in a dictionary that maps each existing category to the category name you desire. \n",
    "\n",
    "***Map categories to fewer ones***: reducing categories in categorical column\n",
    "\n",
    "`operating_system` column is: `'Microsoft'`, `'MacOS'`, `'IOS'`, `'Android'`, `'Linux'`\n",
    "\n",
    "`operating_system` column should become: `'DesktopOS'`, `'MobileOS'`\n",
    "\n",
    "```python\n",
    "# Create mapping dictionary and replace\n",
    "mapping = {'Microsoft':'DesktopOS', 'MacOS':'DesktopOS' , 'Linux':'DesktopOS' , 'IOS':'MobileOS' , 'Android':'MobileOS'}\n",
    "device['operating_system'] = devices['operating_system'].replace(mapping)\n",
    "device['operating_system'].unique()\n",
    "```\n",
    "```\n",
    "array(['DesktopOS', 'MobileOS'], dtype=object)\n",
    "```\n",
    "\n",
    "In this case, this is the mapping dictionary. A quick print of the unique values of operating system shows the mapping has been complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f01e9c-919e-4936-a183-0e86aac9f24b",
   "metadata": {},
   "source": [
    "## Inconsistent categories\n",
    "In this exercise, you'll be revisiting the `airlines` DataFrame from the previous lesson.\n",
    "\n",
    "As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "\n",
    "In this exercise, you will examine two categorical columns from this DataFrame, `dest_region` and `dest_size` respectively, assess how to address them and make sure that they are cleaned and ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc178f2-5280-4052-b91f-fa849e8e63cd",
   "metadata": {},
   "source": [
    "- Print the unique values in `dest_region` and `dest_size` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aeb7525-80a6-4e1a-9f47-f7542a880916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' 'Medium' 'Large' '    Hub' 'Hub        ' '        Small'\n",
      " 'Medium       ' '       Medium' '      Large' 'Small      ' 'Large      ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3cee8f-eca4-4ec4-86e4-28f8a228e9ea",
   "metadata": {},
   "source": [
    "### Question\n",
    "From looking at the output, what do you think is the problem with these columns?\n",
    "\n",
    "1. ~~The `dest_region` column has only inconsistent values due to capitalization.~~\n",
    "\n",
    "2. The `dest_region` column has inconsistent values due to capitalization and has one value that needs to be remapped.\n",
    "\n",
    "3. The `dest_size` column has only inconsistent values due to leading and trailing spaces.\n",
    "\n",
    "**Answer: 2,3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522219c9-b555-4cfe-9609-983a0c8bfec9",
   "metadata": {},
   "source": [
    "- Change the capitalization of all values of `dest_region` to lowercase.\n",
    "- Replace the `'eur'` with `'europe'` in `dest_region` using the `.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de74eead-a451-4324-8f6a-12ae8d52c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb7a1c-fd2f-4101-89db-b864fa3f3cd8",
   "metadata": {},
   "source": [
    "- Strip white spaces from the `dest_size` column using the `.strip()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d32e1c2-8f93-4b13-ad21-180aa545a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fe401-42d7-467b-8078-a5b75a9bf2d2",
   "metadata": {},
   "source": [
    "- Verify that the changes have been into effect by printing the unique values of the columns using `.unique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00d6815e-4a18-46db-9b11-bf020edb8561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249f346-6c0e-4845-88c1-88f26a8ca7d7",
   "metadata": {},
   "source": [
    "## Remapping categories\n",
    "To better understand survey respondents from `airlines`, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "\n",
    "The `airlines` DataFrame contains the `day` and `wait_min` columns, which are categorical and numerical respectively. The `day` column contains the exact day a flight took place, and `wait_min` contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "`wait_type`: `'short'` for 0-60 min, `'medium'` for 60-180 and `long` for 180+\n",
    "`day_week`: `'weekday'` if day is in the weekday, `'weekend'` if day is in the weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c50e7-51e2-4720-86d0-205138cb3f46",
   "metadata": {},
   "source": [
    "- Create the ranges and labels for the `wait_type` column mentioned in the description above.\n",
    "- Create the `wait_type` column by from `wait_min` by using `pd.cut()`, while inputting `label_ranges` and `label_names` in the correct arguments.\n",
    "- Create the `mapping` dictionary mapping weekdays to `'weekday'` and weekend days to `'weekend'`.\n",
    "- Create the `day_week` column by using `.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89f389c1-6638-4bd4-b099-46c75232726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7a09f-25dd-4601-b0b2-a9a99e0140c3",
   "metadata": {},
   "source": [
    "*You just created two new categorical variables, that when combined with other columns, could produce really interesting analysis. Don't forget, you can always use an* `assert` *statement to check your changes passed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fcf5745-415a-44e5-95b4-e531394df24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     wait_type  wait_min day_week\n",
      "0       medium       115  weekday\n",
      "1       medium       135  weekday\n",
      "2       medium        70  weekday\n",
      "3         long       190  weekday\n",
      "4         long       559  weekday\n",
      "...        ...       ...      ...\n",
      "2804      long       280  weekday\n",
      "2805    medium       165  weekday\n",
      "2806    medium        92  weekday\n",
      "2807    medium        95  weekday\n",
      "2808      long       220  weekend\n",
      "\n",
      "[2477 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(airlines[['wait_type', 'wait_min', 'day_week']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cce2db7-79e8-42d1-bd54-0254cab55d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(data=airlines, x='wait_min', y='satisfaction', hue='day_week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f797a-872f-4bfa-a90b-59e8574fb274",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395245c-0045-4c1c-a0d4-6bfa958129ce",
   "metadata": {},
   "source": [
    "## Cleaning text data\n",
    "\n",
    "### What is text data?\n",
    "Text data is one of the most common types of data types. Examples of it range from names, phone numbers, addresses, emails and more. Common text data problems include handling inconsistencies, making sure text data is of a certain length, typos and others.\n",
    "\n",
    "Type of data | Example values\n",
    ":---|:---\n",
    "Names | `Alex`, `Sara`, ...\n",
    "Phone numbers | `+96171679912`, ...\n",
    "Emails | 'emails@email.com', ...\n",
    "Passwords | ...\n",
    "\n",
    "**Common text data problems**\n",
    "1. *Data inconsistency*:\n",
    "    - `+96171679912` or `0096171679912` or ...?\n",
    "2. *Fixed length violations*:\n",
    "    - Passwords needs to be at least * characters\n",
    "3. *Typos*:\n",
    "    - `+961.71.679912`\n",
    "    \n",
    "### Example\n",
    "\n",
    "```python\n",
    "phone = pd.read_csv('phones.csv')\n",
    "print(phones)\n",
    "```\n",
    "We can see that there are phone number values, that begin with 00 or +. We also see that there is one entry where the phone number is 4 digits, which is non-existent. Furthermore, we can see that there are dashes across the phone number column. \n",
    "\n",
    "```\n",
    "              Full name      Phone number\n",
    "0    Prescott D. Gardin  001-879-232-1231\n",
    "1          Gil B. Silva  001-346-345-6122\n",
    "2       Noelani A. Gray  001-702-372-9813\n",
    "3      Reece M. Andrews   +1-297-994-1283   <-- Inconsistent data format\n",
    "4        Hayfa E. Keith  001-335-884-1535\n",
    "5       Benedict Valdez              4153   <-- Length violation\n",
    "6 ...\n",
    "..\n",
    "```\n",
    " If we wanted to feed these phone numbers into an automated call system, or create a report discussing the distribution of users by area code, we couldn't really do so without uniform phone numbers.\n",
    " \n",
    " Ideally, we'd want to the phone number column as such. Where all phone numbers are aligned to begin with 00, where any number below the 10 digit value is replaced with NaN to represent a missing value, and where all dashes have been removed. \n",
    "\n",
    "```\n",
    "              Full name   Phone number\n",
    "0    Prescott D. Gardin  0018792321231\n",
    "1          Gil B. Silva  0013463456122\n",
    "2       Noelani A. Gray  0017023729813\n",
    "3      Reece M. Andrews  0012979941283 \n",
    "4        Hayfa E. Keith            NaN\n",
    "5       Benedict Valdez  0013546154153\n",
    "6 ...\n",
    "..\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956213f3-f456-4424-a6a7-2a06e290f3db",
   "metadata": {},
   "source": [
    "### Fixing the phone number column\n",
    "Let's first begin by replacing the plus sign with 00, to do this, we use the `.str.replace` method which takes in two values, the string being replaced, which is in this case the plus sign and the string to replace it with which is in this case `00`. \n",
    "\n",
    "```python\n",
    "# Replace '+' with '00'\n",
    "phones['Phone number'] = phones['Phone number'].str.replace('+', '00')\n",
    "```\n",
    "\n",
    "We use the same exact technique to remove the dashes, by replacing the dash symbol with an empty string.\n",
    "\n",
    "```python\n",
    "# Replace '-' with nothing\n",
    "phones['Phone number'] = phones['Phone number'].str.replace('-', '')\n",
    "```\n",
    "\n",
    "finally we're going to replace all phone numbers below 10 digits to `NaN`. We can do this by chaining the Phone number column with the `.str.len` method, which returns the string length of each row in the column. We can then use the `.loc` method, to index rows where digits is below `10`, and replace the value of Phone number with numpy's `nan` object.\n",
    "\n",
    "```python\n",
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['Phone number'].str.len()\n",
    "phones.loc[digits < 10, 'Phone number'] = np.nan\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02339e11-0909-49cb-a4f7-9b79d4784257",
   "metadata": {},
   "source": [
    "We can also write `assert` statements to test whether the phone number column has a specific length,and whether it contains the symbols we removed. \n",
    "\n",
    "The first `assert` statement tests that the minimum length of the strings in the phone number column, found through `str.len`, is bigger than or equal to 10.\n",
    "\n",
    "```python\n",
    "# Find length of each row in Phone number column\n",
    "sanity_check = phones['Phone number'].str.len()\n",
    "```\n",
    "```python\n",
    "# Assert minimum phone number length is 10\n",
    "assert sanity_ckeck.min() >= 10\n",
    "```\n",
    "\n",
    "In the second assert statement, we use the `str.contains` method to test whether the phone number column contains a specific pattern. It returns a series of booleans for that are `True` for matches and `False` for non-matches. We set the pattern plus bar pipe minus, the bar pipe here is basically an or statement, so we're trying to find matches for either symbols. We chain it with the any method which returns `True` if any element in the output of our `.str.contains` is `True`, and test whether the it returns `False`.\n",
    "\n",
    "```python\n",
    "# Assert all numbers do not have '+' or '-'\n",
    "assert phones['Phone number'].str.contains('+|-').any() == False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd55d6-c9ba-4788-b6c1-0e36ba1d5783",
   "metadata": {},
   "source": [
    "### But what about more complicated examples?\n",
    "But what about more complicated examples? How can we clean a phone number column that looks like this for example? \n",
    "\n",
    "```python\n",
    "phones.head()\n",
    "```\n",
    "```\n",
    "              Full name     Phone number\n",
    "0    Prescott D. Gardin  +(01879)-321231\n",
    "1          Gil B. Silva    +0134-6346122\n",
    "2       Noelani A. Gray       +0017-9813\n",
    "3      Reece M. Andrews    +01297-941283 \n",
    "4        Hayfa E. Keith   +(016977)-8423\n",
    "```\n",
    "\n",
    "Where phone numbers can contain a range of symbols from plus signs, dashes, parenthesis and maybe more. This is where **regular expressions** come in. \n",
    "\n",
    "**Regular expressions** give us the ability to search for any pattern in text data, like only digits for example. They are like control + find in your browser, but way more dynamic and robust.\n",
    "\n",
    "### Regular expressions in action\n",
    "Here we are attempting to only extract digits from the phone number column. To do this, we use the `.str.replace` method with the pattern we want to replace with an empty string. Notice the pattern fed into the method. This is essentially us telling pandas to replace anything that is not a digit with nothing. They are immensely useful for difficult string cleaning tasks\n",
    "\n",
    "```python\n",
    "# Replace letters with nothing\n",
    "phones['Phone number'] = phones['Phone number'].str.replace(r'\\D+', '')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3cad4-3343-436c-a856-26e44226c650",
   "metadata": {},
   "source": [
    "## Removing titles and taking names\n",
    "While collecting survey respondent metadata in the `airlines` DataFrame, the full name of respondents was saved in the `full_name` column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as `\"Dr.\"`, `\"Mr.\"`, `\"Ms.\"` and `\"Miss\"`.\n",
    "\n",
    "Your ultimate objective is to create two new columns named `first_name` and `last_name`, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "\n",
    "- Remove `\"Dr.\"`, `\"Mr.\"`, `\"Miss\"` and `\"Ms.\"` from `full_name` by replacing them with an empty string `\"\"` in that order.\n",
    "- Run the `assert` statement using `.str.contains()` that tests whether `full_name` still contains any of the honorifics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1a7c4-0af0-469d-b8c4-fdfa0089702e",
   "metadata": {},
   "source": [
    "```python\n",
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Dr.', '')\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Mr.', '')\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Miss', '')\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Ms.', '')\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bccb0b8-c998-4a99-8f3a-8ba483d2786c",
   "metadata": {},
   "source": [
    "## Keeping it descriptive\n",
    "To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "\n",
    "Their response is stored in the `survey_response` column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than ***40*** , and make sure your new DataFrame contains responses with ***40*** characters or more using an `assert` statement.\n",
    "\n",
    "- Using the `airlines` DataFrame, store the length of each instance in the `survey_response` column in `resp_length` by using `.str.len()`.\n",
    "- Isolate the rows of `airlines` with `resp_length` higher than `40`.\n",
    "- Assert that the smallest survey response length in `airlines_survey` is now bigger than `40`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90124fab-3cee-4abb-8398-b3a2beb8a358",
   "metadata": {},
   "source": [
    "```python\n",
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])\n",
    "```\n",
    "\n",
    "```\n",
    "output:\n",
    "    18    The airport personnell forgot to alert us of d...\n",
    "    19    The food in the airport was really really expe...\n",
    "    20    One of the other travelers was really loud and...\n",
    "    21    I don't remember answering the survey with the...\n",
    "    22    The airport personnel kept ignoring my request...\n",
    "    23    The chair I sat in was extremely uncomfortable...\n",
    "    24    I wish you were more like other airports, the ...\n",
    "    25    I was really unsatisfied with the wait times b...\n",
    "    27    The flight was okay, but I didn't really like ...\n",
    "    28    We were really slowed down by security measure...\n",
    "    29    There was a spill on the aisle next to the bat...\n",
    "    30    I felt very unsatisfied by how long the flight...\n",
    "    Name: survey_response, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d69349-7071-4ef0-bb13-910377761427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
